{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>DATA 401 Project 3 Code</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the code used for Project 3 for Group 6 (Flo Costa, Anish Yakkala, and Zachary Gelber). Comments and text blocks have been added to most of the code below to explain their use and function. Please consult the accompanying README file for how to run different sections of the code.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Dataset Creation and Feature Engineering</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***In this section we split the data into a training, validation, and testing set, fill in missing values using a modified K-Nearest Neighbors algorithm, and use forward stepwise regression to determine our most informative variables from the data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we import the needed packages to build and evaluate our linear regresion model and neural network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\speed\\Documents\\Senior Year (2020-2021)\\Fall Quarter\\Data 401\\Project 3\\sberbank-russian-housing-market\n",
      "C:\\Users\\speed\\Documents\\Senior Year (2020-2021)\\Fall Quarter\\Data 401\\Project 3\\sberbank-russian-housing-market\\sberbank-russian-housing-market\n"
     ]
    }
   ],
   "source": [
    "%cd sberbank-russian-housing-market\n",
    "%cd sberbank-russian-housing-market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we move into the directory containing the necessary data files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>...</th>\n",
       "      <th>provision_retail_space_modern_sqm</th>\n",
       "      <th>turnover_catering_per_cap</th>\n",
       "      <th>theaters_viewers_per_1000_cap</th>\n",
       "      <th>seats_theather_rfmin_per_100000_cap</th>\n",
       "      <th>museum_visitis_per_100_cap</th>\n",
       "      <th>bandwidth_sports</th>\n",
       "      <th>population_reg_sports_share</th>\n",
       "      <th>students_reg_sports_share</th>\n",
       "      <th>apartment_build</th>\n",
       "      <th>apartment_fund_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-20</td>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-08-27</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
       "0   1  2011-08-20       43     27.0    4.0        NaN       NaN         NaN   \n",
       "1   2  2011-08-23       34     19.0    3.0        NaN       NaN         NaN   \n",
       "2   3  2011-08-27       43     29.0    2.0        NaN       NaN         NaN   \n",
       "3   4  2011-09-01       89     50.0    9.0        NaN       NaN         NaN   \n",
       "4   5  2011-09-05       77     77.0    4.0        NaN       NaN         NaN   \n",
       "\n",
       "   num_room  kitch_sq  ...  provision_retail_space_modern_sqm  \\\n",
       "0       NaN       NaN  ...                              271.0   \n",
       "1       NaN       NaN  ...                              271.0   \n",
       "2       NaN       NaN  ...                              271.0   \n",
       "3       NaN       NaN  ...                              271.0   \n",
       "4       NaN       NaN  ...                              271.0   \n",
       "\n",
       "  turnover_catering_per_cap theaters_viewers_per_1000_cap  \\\n",
       "0                    6943.0                         565.0   \n",
       "1                    6943.0                         565.0   \n",
       "2                    6943.0                         565.0   \n",
       "3                    6943.0                         565.0   \n",
       "4                    6943.0                         565.0   \n",
       "\n",
       "   seats_theather_rfmin_per_100000_cap  museum_visitis_per_100_cap  \\\n",
       "0                              0.45356                      1240.0   \n",
       "1                              0.45356                      1240.0   \n",
       "2                              0.45356                      1240.0   \n",
       "3                              0.45356                      1240.0   \n",
       "4                              0.45356                      1240.0   \n",
       "\n",
       "   bandwidth_sports  population_reg_sports_share  students_reg_sports_share  \\\n",
       "0          269768.0                        22.37                      64.12   \n",
       "1          269768.0                        22.37                      64.12   \n",
       "2          269768.0                        22.37                      64.12   \n",
       "3          269768.0                        22.37                      64.12   \n",
       "4          269768.0                        22.37                      64.12   \n",
       "\n",
       "   apartment_build  apartment_fund_sqm  \n",
       "0          23587.0            230310.0  \n",
       "1          23587.0            230310.0  \n",
       "2          23587.0            230310.0  \n",
       "3          23587.0            230310.0  \n",
       "4          23587.0            230310.0  \n",
       "\n",
       "[5 rows x 391 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "macro = pd.read_csv('macro.csv')\n",
    "\n",
    "df_merge = df.merge(right = macro, how = \"left\", on = \"timestamp\")\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we read in our two main data files: \"train.csv\" and \"macro.csv\". The former contains specific information about the property and the surrounding area, while the latter contains macroeconomic information for dates from August 20th, 2011 to XXXXXXXXXX, 2016. Since \"train.csv\" also has a variable for date of transaction, we perform a join the two data sets by date. Notice that even in the few listings seen above, many missing values can be seen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_toss_na = [\"provision_retail_space_modern_sqm\", \n",
    "             \"provision_retail_space_sqm\", \n",
    "             \"students_reg_sports_share\",\n",
    "             \"museum_visitis_per_100_cap\",\n",
    "             \"theaters_viewers_per_1000_cap\",\n",
    "             \"load_of_teachers_preschool_per_teacher\",\n",
    "             \"hospital_beds_raion\"]    #Thrown out because too many NaN values.\n",
    "\n",
    "to_toss_geo = [\"sub_area\",\n",
    "              \"ID_railroad_station_walk\",\n",
    "              \"ID_railroad_station_avto\",\n",
    "              \"ID_big_road1\",\n",
    "              \"ID_big_road2\",\n",
    "              \"ID_railroad_terminal\",\n",
    "              \"ID_bus_terminal\"]       #Thrown out because they are categorical variables \n",
    "                                       #for geographic locations, which are not allowed to \n",
    "                                       #be dummified.\n",
    "\n",
    "to_toss_ind = [\"culture_objects_top_25\",\n",
    "              \"thermal_power_plant_raion\",\n",
    "              \"incineration_raion\",\n",
    "              \"oil_chemistry_raion\",\n",
    "              \"railroad_terminal_raion\",\n",
    "              \"big_market_raion\",\n",
    "              \"nuclear_reactor_raion\",\n",
    "              \"detention_facility_raion\",\n",
    "              \"water_1line\",\n",
    "              \"big_road1_1line\",\n",
    "              \"railroad_1line\",\n",
    "              \"radiation_raion\"]     #Thrown out as they are redundant indicator variables. For\n",
    "                                     #each of these there exists a more detailed numeric version.\n",
    "\n",
    "to_toss_weird = [\"child_on_acc_pre_school\",\n",
    "                \"modern_education_share\",\n",
    "                \"old_education_build_share\"]     #Thrown out because they contain weird values.\n",
    "                                                 #Should discuss if they are worth keeping.\n",
    "\n",
    "to_dummify = [\"product_type\",\n",
    "             \"ecology\",\n",
    "             \"material\",\n",
    "             \"state\"]      #These are the variables that need to be dummified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not every variable in this data set is useful. Although our goal is for the neural networks to parse out relevant information to predict housing prices, we can aid this process by pre-emptively removing variables that we believe will not contribute to the model. By manually going through each variable, we can make decisions about whether or not to consider it in our models.**\n",
    "\n",
    "**First, we threw out variables that had too many missing values. Although we will later try to fill in these missings values using K-Nearest Neighbors, this becomes more difficult if most of the data is already missing. Furthermore, it is questionable how useful a variable can be if most the data is not even there. For example, the variable \"provision_retail_space_modern_sqm\" was missing over 95% of its values. Next, we threw out variables regarding geographic information, as these were forbidden by the project specifications. Then, we tossed out variables we believed were redundant. For example, \"thermal_power_plant_raion\" is a \"yes/no\" variable that indicates if a property is near a thermal power plant. However, there also exists a variable called \"thermal_power_plant_km\" that indicates the distance in kilometers from a property to the nearest thermal power plant. Since these variables describe nearly the same thing, we felt it made little sense to keep both, so we tossed the former. Finally, we also tossed variables that had some strange values.**\n",
    "\n",
    "**We also created a list of categorical variables that would need to be dummified later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_val_size = int(len(df_merge)*0.2)\n",
    "test_and_val_idx = rand.sample(list(range(len(df_merge))),test_and_val_size)\n",
    "\n",
    "val_idx = rand.sample(test_and_val_idx,int(test_and_val_size/2))\n",
    "test_idx = list(set(test_and_val_idx) - set(val_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we set the indexes for the validation and testing set, leaving the rest for the training set. We chose to do an 80%/10%/10% split for the training, validation, and testing respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>...</th>\n",
       "      <th>material_2.0</th>\n",
       "      <th>material_3.0</th>\n",
       "      <th>material_4.0</th>\n",
       "      <th>material_5.0</th>\n",
       "      <th>material_6.0</th>\n",
       "      <th>state_1.0</th>\n",
       "      <th>state_2.0</th>\n",
       "      <th>state_3.0</th>\n",
       "      <th>state_4.0</th>\n",
       "      <th>state_33.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.407578e+06</td>\n",
       "      <td>155572</td>\n",
       "      <td>0.189727</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.808270e+06</td>\n",
       "      <td>101708</td>\n",
       "      <td>0.112560</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.398461e+06</td>\n",
       "      <td>108171</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.506452e+06</td>\n",
       "      <td>43795</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.032047e+07</td>\n",
       "      <td>57405</td>\n",
       "      <td>0.523439</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   full_sq  life_sq  floor  max_floor  build_year  num_room  kitch_sq  \\\n",
       "0       43     27.0    4.0        NaN         NaN       NaN       NaN   \n",
       "2       43     29.0    2.0        NaN         NaN       NaN       NaN   \n",
       "4       77     77.0    4.0        NaN         NaN       NaN       NaN   \n",
       "5       67     46.0   14.0        NaN         NaN       NaN       NaN   \n",
       "6       25     14.0   10.0        NaN         NaN       NaN       NaN   \n",
       "\n",
       "         area_m  raion_popul  green_zone_part  ...  material_2.0  \\\n",
       "0  6.407578e+06       155572         0.189727  ...           NaN   \n",
       "2  4.808270e+06       101708         0.112560  ...           NaN   \n",
       "4  8.398461e+06       108171         0.015234  ...           NaN   \n",
       "5  7.506452e+06        43795         0.007670  ...           NaN   \n",
       "6  1.032047e+07        57405         0.523439  ...           NaN   \n",
       "\n",
       "   material_3.0  material_4.0  material_5.0  material_6.0  state_1.0  \\\n",
       "0           NaN           NaN           NaN           NaN        NaN   \n",
       "2           NaN           NaN           NaN           NaN        NaN   \n",
       "4           NaN           NaN           NaN           NaN        NaN   \n",
       "5           NaN           NaN           NaN           NaN        NaN   \n",
       "6           NaN           NaN           NaN           NaN        NaN   \n",
       "\n",
       "   state_2.0  state_3.0  state_4.0  state_33.0  \n",
       "0        NaN        NaN        NaN         NaN  \n",
       "2        NaN        NaN        NaN         NaN  \n",
       "4        NaN        NaN        NaN         NaN  \n",
       "5        NaN        NaN        NaN         NaN  \n",
       "6        NaN        NaN        NaN         NaN  \n",
       "\n",
       "[5 rows x 373 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_merge.loc[~df_merge.index.isin(test_and_val_idx)]\n",
    "y_train = df_train[\"price_doc\"]\n",
    "df_train = df_train.drop(to_toss_na + to_toss_geo + to_toss_ind + to_toss_weird + [\"timestamp\",\"id\",\"price_doc\"], axis=1)\n",
    "df_train = pd.get_dummies(df_train, columns = to_dummify)\n",
    "df_train.loc[df_train[\"build_year\"] < 1500, \"build_year\"] = np.nan\n",
    "\n",
    "false_dummies = [\"raion_build_count_with_material_info\", \"students_state_oneshift\"]\n",
    "\n",
    "for dummy in to_dummify:\n",
    "    dummy_col_list = [col for col in df_train.columns if dummy + \"_\" in col and col not in false_dummies]\n",
    "    mask = df_train[dummy_col_list].sum(axis=1) == 0\n",
    "    df_train.loc[mask,dummy_col_list] = float('NaN')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we create our training set based on the indexes randomized above. After dropping the problematic variables discussed earlier, we dummify the categorical variables we also listed. Additionally, we also set any listings with a build year of less than 1500 to NaN. This is because some listings of build years of 0 or 1, which we believed to indicate missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>...</th>\n",
       "      <th>ecology_satisfactory</th>\n",
       "      <th>material_1.0</th>\n",
       "      <th>material_2.0</th>\n",
       "      <th>material_4.0</th>\n",
       "      <th>material_5.0</th>\n",
       "      <th>material_6.0</th>\n",
       "      <th>state_1.0</th>\n",
       "      <th>state_2.0</th>\n",
       "      <th>state_3.0</th>\n",
       "      <th>state_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>42</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.615514e+07</td>\n",
       "      <td>178264</td>\n",
       "      <td>0.137846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>58</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.462270e+06</td>\n",
       "      <td>129207</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14679</th>\n",
       "      <td>77</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.792845e+06</td>\n",
       "      <td>21155</td>\n",
       "      <td>0.528252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14667</th>\n",
       "      <td>35</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.428699e+07</td>\n",
       "      <td>157010</td>\n",
       "      <td>0.389354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>73</td>\n",
       "      <td>42.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.333221e+06</td>\n",
       "      <td>64931</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  floor  max_floor  build_year  num_room  kitch_sq  \\\n",
       "228         42     19.0    9.0        NaN         NaN       NaN       NaN   \n",
       "2611        58     43.0    6.0        NaN         NaN       NaN       NaN   \n",
       "14679       77     39.0   16.0       18.0      2004.0       2.0      17.0   \n",
       "14667       35     34.0    8.0        9.0      1972.0       1.0       7.0   \n",
       "4718        73     42.0   13.0        NaN         NaN       NaN       NaN   \n",
       "\n",
       "             area_m  raion_popul  green_zone_part  ...  ecology_satisfactory  \\\n",
       "228    2.615514e+07       178264         0.137846  ...                   1.0   \n",
       "2611   7.462270e+06       129207         0.387100  ...                   0.0   \n",
       "14679  7.792845e+06        21155         0.528252  ...                   0.0   \n",
       "14667  1.428699e+07       157010         0.389354  ...                   0.0   \n",
       "4718   5.333221e+06        64931         0.074077  ...                   0.0   \n",
       "\n",
       "       material_1.0  material_2.0  material_4.0  material_5.0  material_6.0  \\\n",
       "228             NaN           NaN           NaN           NaN           NaN   \n",
       "2611            NaN           NaN           NaN           NaN           NaN   \n",
       "14679           0.0           0.0           0.0           0.0           1.0   \n",
       "14667           1.0           0.0           0.0           0.0           0.0   \n",
       "4718            NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "       state_1.0  state_2.0  state_3.0  state_4.0  \n",
       "228          NaN        NaN        NaN        NaN  \n",
       "2611         NaN        NaN        NaN        NaN  \n",
       "14679        0.0        0.0        1.0        0.0  \n",
       "14667        0.0        1.0        0.0        0.0  \n",
       "4718         NaN        NaN        NaN        NaN  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = df_merge.loc[val_idx]\n",
    "y_val = df_val[\"price_doc\"]\n",
    "df_val = df_val.drop(to_toss_na + to_toss_geo + to_toss_ind + to_toss_weird + [\"timestamp\",\"id\",\"price_doc\"], axis=1)\n",
    "df_val = pd.get_dummies(df_val, columns = to_dummify)\n",
    "df_val.loc[df_val[\"build_year\"] < 1500, \"build_year\"] = np.nan\n",
    "\n",
    "false_dummies = [\"raion_build_count_with_material_info\", \"students_state_oneshift\"]\n",
    "\n",
    "for dummy in to_dummify:\n",
    "    dummy_col_list = [col for col in df_val.columns if dummy + \"_\" in col and col not in false_dummies]\n",
    "    mask = df_val[dummy_col_list].sum(axis=1) == 0\n",
    "    df_val.loc[mask,dummy_col_list] = float('NaN')\n",
    "\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we repeat exactly what we did for the training set, only this time for the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>...</th>\n",
       "      <th>ecology_satisfactory</th>\n",
       "      <th>material_1.0</th>\n",
       "      <th>material_2.0</th>\n",
       "      <th>material_4.0</th>\n",
       "      <th>material_5.0</th>\n",
       "      <th>material_6.0</th>\n",
       "      <th>state_1.0</th>\n",
       "      <th>state_2.0</th>\n",
       "      <th>state_3.0</th>\n",
       "      <th>state_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16385</th>\n",
       "      <td>41</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.250576e+07</td>\n",
       "      <td>61396</td>\n",
       "      <td>0.403651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.258354e+07</td>\n",
       "      <td>178473</td>\n",
       "      <td>0.194703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.787424e+06</td>\n",
       "      <td>96959</td>\n",
       "      <td>0.038456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24584</th>\n",
       "      <td>38</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.292112e+06</td>\n",
       "      <td>73148</td>\n",
       "      <td>0.063747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24587</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.084231e+07</td>\n",
       "      <td>85219</td>\n",
       "      <td>0.062172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  floor  max_floor  build_year  num_room  kitch_sq  \\\n",
       "16385       41     26.0    1.0        5.0      1962.0       2.0       5.0   \n",
       "3           89     50.0    9.0        NaN         NaN       NaN       NaN   \n",
       "8           42     27.0    5.0        NaN         NaN       NaN       NaN   \n",
       "24584       38     18.0   16.0       16.0      1973.0       1.0       9.0   \n",
       "24587       42      NaN   14.0       18.0         NaN       1.0       1.0   \n",
       "\n",
       "             area_m  raion_popul  green_zone_part  ...  ecology_satisfactory  \\\n",
       "16385  1.250576e+07        61396         0.403651  ...                   0.0   \n",
       "3      1.258354e+07       178473         0.194703  ...                   0.0   \n",
       "8      4.787424e+06        96959         0.038456  ...                   0.0   \n",
       "24584  3.292112e+06        73148         0.063747  ...                   0.0   \n",
       "24587  1.084231e+07        85219         0.062172  ...                   0.0   \n",
       "\n",
       "       material_1.0  material_2.0  material_4.0  material_5.0  material_6.0  \\\n",
       "16385           1.0           0.0           0.0           0.0           0.0   \n",
       "3               NaN           NaN           NaN           NaN           NaN   \n",
       "8               NaN           NaN           NaN           NaN           NaN   \n",
       "24584           0.0           0.0           0.0           1.0           0.0   \n",
       "24587           1.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "       state_1.0  state_2.0  state_3.0  state_4.0  \n",
       "16385        0.0        1.0        0.0        0.0  \n",
       "3            NaN        NaN        NaN        NaN  \n",
       "8            NaN        NaN        NaN        NaN  \n",
       "24584        0.0        0.0        1.0        0.0  \n",
       "24587        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_merge.loc[test_idx]\n",
    "y_test = df_test[\"price_doc\"]\n",
    "df_test = df_test.drop(to_toss_na + to_toss_geo + to_toss_ind + to_toss_weird + [\"timestamp\",\"id\",\"price_doc\"], axis=1)\n",
    "df_test = pd.get_dummies(df_test, columns = to_dummify)\n",
    "df_test.loc[df_test[\"build_year\"] < 1500, \"build_year\"] = np.nan\n",
    "\n",
    "false_dummies = [\"raion_build_count_with_material_info\", \"students_state_oneshift\"]\n",
    "\n",
    "for dummy in to_dummify:\n",
    "    dummy_col_list = [col for col in df_test.columns if dummy + \"_\" in col and col not in false_dummies]\n",
    "    mask = df_test[dummy_col_list].sum(axis=1) == 0\n",
    "    df_test.loc[mask,dummy_col_list] = float('NaN')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again we repeat what we did for the training and validation set, only this time on the testing set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_dummies = [\"state_33.0\", \"material_3.0\", \"ecology_no data\"]\n",
    "df_train.drop(bad_dummies, axis=1, inplace=True, errors='ignore')\n",
    "df_val.drop(bad_dummies, axis=1, inplace=True, errors='ignore')\n",
    "df_test.drop(bad_dummies, axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some of the categories in our categorical variables are outliers or mistakes. The category \"state_33.0\" and \"material_3.0\", for example, have only one listing in the entire data set. Thus we think they are either mistakes or incredibly rare. Either way, we do not think they are worth keeping. The category \"ecology_no data\" is obviously a version of a missing variable, so we simply drop it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>indust_part</th>\n",
       "      <th>children_preschool</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>children_school</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>...</th>\n",
       "      <th>turnover_catering_per_cap</th>\n",
       "      <th>seats_theather_rfmin_per_100000_cap</th>\n",
       "      <th>bandwidth_sports</th>\n",
       "      <th>apartment_fund_sqm</th>\n",
       "      <th>product_type_Investment</th>\n",
       "      <th>product_type_OwnerOccupier</th>\n",
       "      <th>ecology_excellent</th>\n",
       "      <th>ecology_good</th>\n",
       "      <th>ecology_poor</th>\n",
       "      <th>ecology_satisfactory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.276134</td>\n",
       "      <td>-0.547093</td>\n",
       "      <td>1.235106</td>\n",
       "      <td>-0.167852</td>\n",
       "      <td>-0.999331</td>\n",
       "      <td>1.161374</td>\n",
       "      <td>0.312110</td>\n",
       "      <td>1.240210</td>\n",
       "      <td>0.085088</td>\n",
       "      <td>-0.32857</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.254393</td>\n",
       "      <td>1.060682</td>\n",
       "      <td>-1.755026</td>\n",
       "      <td>0.256394</td>\n",
       "      <td>0.752342</td>\n",
       "      <td>-0.752342</td>\n",
       "      <td>-0.385354</td>\n",
       "      <td>1.800638</td>\n",
       "      <td>-0.597033</td>\n",
       "      <td>-0.371398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.276134</td>\n",
       "      <td>-0.624829</td>\n",
       "      <td>0.303941</td>\n",
       "      <td>-0.609123</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>0.192293</td>\n",
       "      <td>-0.021983</td>\n",
       "      <td>0.211982</td>\n",
       "      <td>0.665366</td>\n",
       "      <td>-0.32857</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.254393</td>\n",
       "      <td>1.060682</td>\n",
       "      <td>-1.755026</td>\n",
       "      <td>0.256394</td>\n",
       "      <td>0.752342</td>\n",
       "      <td>-0.752342</td>\n",
       "      <td>-0.385354</td>\n",
       "      <td>-0.555336</td>\n",
       "      <td>1.674880</td>\n",
       "      <td>-0.371398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.559859</td>\n",
       "      <td>-0.450324</td>\n",
       "      <td>0.415669</td>\n",
       "      <td>-1.165666</td>\n",
       "      <td>-0.685397</td>\n",
       "      <td>0.146946</td>\n",
       "      <td>0.980298</td>\n",
       "      <td>0.347592</td>\n",
       "      <td>1.245643</td>\n",
       "      <td>-0.32857</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.254393</td>\n",
       "      <td>1.060682</td>\n",
       "      <td>-1.755026</td>\n",
       "      <td>0.256394</td>\n",
       "      <td>0.752342</td>\n",
       "      <td>-0.752342</td>\n",
       "      <td>2.594907</td>\n",
       "      <td>-0.555336</td>\n",
       "      <td>-0.597033</td>\n",
       "      <td>-0.371398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.313979</td>\n",
       "      <td>-0.493681</td>\n",
       "      <td>-0.697222</td>\n",
       "      <td>-1.208917</td>\n",
       "      <td>3.098435</td>\n",
       "      <td>-0.714925</td>\n",
       "      <td>-0.690171</td>\n",
       "      <td>-0.713723</td>\n",
       "      <td>-0.495189</td>\n",
       "      <td>-0.32857</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.254393</td>\n",
       "      <td>1.060682</td>\n",
       "      <td>-1.755026</td>\n",
       "      <td>0.256394</td>\n",
       "      <td>0.752342</td>\n",
       "      <td>-0.752342</td>\n",
       "      <td>-0.385354</td>\n",
       "      <td>-0.555336</td>\n",
       "      <td>1.674880</td>\n",
       "      <td>-0.371398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.718718</td>\n",
       "      <td>-0.356902</td>\n",
       "      <td>-0.461941</td>\n",
       "      <td>1.740428</td>\n",
       "      <td>-0.643331</td>\n",
       "      <td>-0.704178</td>\n",
       "      <td>0.312110</td>\n",
       "      <td>-0.639526</td>\n",
       "      <td>0.085088</td>\n",
       "      <td>-0.32857</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.254393</td>\n",
       "      <td>1.060682</td>\n",
       "      <td>-1.755026</td>\n",
       "      <td>0.256394</td>\n",
       "      <td>0.752342</td>\n",
       "      <td>-0.752342</td>\n",
       "      <td>-0.385354</td>\n",
       "      <td>-0.555336</td>\n",
       "      <td>1.674880</td>\n",
       "      <td>-0.371398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    full_sq    area_m  raion_popul  green_zone_part  indust_part  \\\n",
       "0 -0.276134 -0.547093     1.235106        -0.167852    -0.999331   \n",
       "2 -0.276134 -0.624829     0.303941        -0.609123    -0.000820   \n",
       "4  0.559859 -0.450324     0.415669        -1.165666    -0.685397   \n",
       "5  0.313979 -0.493681    -0.697222        -1.208917     3.098435   \n",
       "6 -0.718718 -0.356902    -0.461941         1.740428    -0.643331   \n",
       "\n",
       "   children_preschool  preschool_education_centers_raion  children_school  \\\n",
       "0            1.161374                           0.312110         1.240210   \n",
       "2            0.192293                          -0.021983         0.211982   \n",
       "4            0.146946                           0.980298         0.347592   \n",
       "5           -0.714925                          -0.690171        -0.713723   \n",
       "6           -0.704178                           0.312110        -0.639526   \n",
       "\n",
       "   school_education_centers_raion  school_education_centers_top_20_raion  ...  \\\n",
       "0                        0.085088                               -0.32857  ...   \n",
       "2                        0.665366                               -0.32857  ...   \n",
       "4                        1.245643                               -0.32857  ...   \n",
       "5                       -0.495189                               -0.32857  ...   \n",
       "6                        0.085088                               -0.32857  ...   \n",
       "\n",
       "   turnover_catering_per_cap  seats_theather_rfmin_per_100000_cap  \\\n",
       "0                  -3.254393                             1.060682   \n",
       "2                  -3.254393                             1.060682   \n",
       "4                  -3.254393                             1.060682   \n",
       "5                  -3.254393                             1.060682   \n",
       "6                  -3.254393                             1.060682   \n",
       "\n",
       "   bandwidth_sports  apartment_fund_sqm  product_type_Investment  \\\n",
       "0         -1.755026            0.256394                 0.752342   \n",
       "2         -1.755026            0.256394                 0.752342   \n",
       "4         -1.755026            0.256394                 0.752342   \n",
       "5         -1.755026            0.256394                 0.752342   \n",
       "6         -1.755026            0.256394                 0.752342   \n",
       "\n",
       "   product_type_OwnerOccupier  ecology_excellent  ecology_good  ecology_poor  \\\n",
       "0                   -0.752342          -0.385354      1.800638     -0.597033   \n",
       "2                   -0.752342          -0.385354     -0.555336      1.674880   \n",
       "4                   -0.752342           2.594907     -0.555336     -0.597033   \n",
       "5                   -0.752342          -0.385354     -0.555336      1.674880   \n",
       "6                   -0.752342          -0.385354     -0.555336      1.674880   \n",
       "\n",
       "   ecology_satisfactory  \n",
       "0             -0.371398  \n",
       "2             -0.371398  \n",
       "4             -0.371398  \n",
       "5             -0.371398  \n",
       "6             -0.371398  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_sum = df_train.isna().sum()\n",
    "no_nan_cols = na_sum[na_sum == 0].index\n",
    "df_knn = df_train[no_nan_cols]\n",
    "knn_mean = df_knn.mean()\n",
    "knn_std = df_knn.std()\n",
    "df_knn = (df_knn - knn_mean)/(knn_std)\n",
    "df_knn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our goal is to use K-Nearest Neighbors to try and fill in the missing values. To determine the neighbors of a particular listing, we use the data frame created above, \"df_knn\". This data frame contains only variables that have no missing values, as well as standardized versions of each value. Thus we can use that to determine the closest neighbors of any particular listing by calculating the Euclidean distance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 5            \n",
    "\n",
    "for i in df_train.index:\n",
    "  curr_row = df_train.loc[i]\n",
    "  if curr_row.isna().sum() > 0:\n",
    "    curr_nan_cols = curr_row[curr_row.isna()].index\n",
    "    curr_row_knn = df_knn.loc[i]\n",
    "    nearest = df_knn.subtract(curr_row_knn,axis=1).pow(2).sum(axis=1).sort_values().index\n",
    "    curr_nan_cols_dict = {col: [] for col in curr_nan_cols}\n",
    "    k_limit = k*len(curr_nan_cols)\n",
    "    for j in nearest:\n",
    "      if j != i:\n",
    "        for col in curr_nan_cols:\n",
    "          if len(curr_nan_cols_dict[col]) < k:\n",
    "            curr_cell = df_train.loc[j][col]\n",
    "            if not np.isnan(curr_cell):\n",
    "              curr_nan_cols_dict[col].append(curr_cell)\n",
    "              k_limit -= 1\n",
    "      if k_limit == 0:\n",
    "        for key in curr_nan_cols_dict.keys():\n",
    "          df_train.loc[i,key] = pd.Series(curr_nan_cols_dict[key]).mean()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we implement our K-Nearest Neighbors algorithm. First, we iterate through each element of \"df_train\". If it does not contain any missing values, we move on. Otherwise, we use \"df_knn\" to create a sorted list of its closet neighbors. We also create a dictionary for each missing value of the current listing. We then iterate through this list, adding values from the neighbors to the corresponding list of the dictionary if it is not missing. We repeat this until each list in the dictionary has k elements (for our project we chose k = 5). Then we take the mean of that list and use it to fill in the missing value. We then repeat this process for the next element of \"df_train\" until we are done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"df_train_vfinal\")   #Used to save output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above process can take a few hours to complete, so we save the output to save time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>...</th>\n",
       "      <th>ecology_satisfactory</th>\n",
       "      <th>material_1.0</th>\n",
       "      <th>material_2.0</th>\n",
       "      <th>material_4.0</th>\n",
       "      <th>material_5.0</th>\n",
       "      <th>material_6.0</th>\n",
       "      <th>state_1.0</th>\n",
       "      <th>state_2.0</th>\n",
       "      <th>state_3.0</th>\n",
       "      <th>state_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.600</td>\n",
       "      <td>1974.200</td>\n",
       "      <td>2.400</td>\n",
       "      <td>6.600</td>\n",
       "      <td>6.407578e+06</td>\n",
       "      <td>155572</td>\n",
       "      <td>0.189727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.720</td>\n",
       "      <td>1972.840</td>\n",
       "      <td>1.880</td>\n",
       "      <td>7.120</td>\n",
       "      <td>9.589337e+06</td>\n",
       "      <td>115352</td>\n",
       "      <td>0.372602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.464</td>\n",
       "      <td>1967.808</td>\n",
       "      <td>2.256</td>\n",
       "      <td>5.944</td>\n",
       "      <td>4.808270e+06</td>\n",
       "      <td>101708</td>\n",
       "      <td>0.112560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.664</td>\n",
       "      <td>1987.408</td>\n",
       "      <td>2.256</td>\n",
       "      <td>8.544</td>\n",
       "      <td>1.258354e+07</td>\n",
       "      <td>178473</td>\n",
       "      <td>0.194703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.200</td>\n",
       "      <td>1940.200</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.200</td>\n",
       "      <td>8.398461e+06</td>\n",
       "      <td>108171</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   full_sq  life_sq  floor  max_floor  build_year  num_room  kitch_sq  \\\n",
       "0       43     27.0    4.0     10.600    1974.200     2.400     6.600   \n",
       "1       34     19.0    3.0     12.720    1972.840     1.880     7.120   \n",
       "2       43     29.0    2.0      8.464    1967.808     2.256     5.944   \n",
       "3       89     50.0    9.0     14.664    1987.408     2.256     8.544   \n",
       "4       77     77.0    4.0      4.200    1940.200     3.000     5.200   \n",
       "\n",
       "         area_m  raion_popul  green_zone_part  ...  ecology_satisfactory  \\\n",
       "0  6.407578e+06       155572         0.189727  ...                   0.0   \n",
       "1  9.589337e+06       115352         0.372602  ...                   0.0   \n",
       "2  4.808270e+06       101708         0.112560  ...                   0.0   \n",
       "3  1.258354e+07       178473         0.194703  ...                   0.0   \n",
       "4  8.398461e+06       108171         0.015234  ...                   0.0   \n",
       "\n",
       "   material_1.0  material_2.0  material_4.0  material_5.0  material_6.0  \\\n",
       "0         0.800           0.0           0.0         0.200           0.0   \n",
       "1         0.760           0.0           0.0         0.240           0.0   \n",
       "2         0.512           0.4           0.0         0.088           0.0   \n",
       "3         0.912           0.0           0.0         0.088           0.0   \n",
       "4         0.200           0.8           0.0         0.000           0.0   \n",
       "\n",
       "   state_1.0  state_2.0  state_3.0  state_4.0  \n",
       "0        0.0      0.400      0.600        0.0  \n",
       "1        0.0      0.280      0.720        0.0  \n",
       "2        0.0      0.736      0.264        0.0  \n",
       "3        0.0      0.136      0.864        0.0  \n",
       "4        0.2      0.400      0.400        0.0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"df_train_vfinal\",index_col = \"Unnamed: 0\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we read in our output from before for \"df_train\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "counter = 0\n",
    "\n",
    "for i in df_val.index:\n",
    "  curr_row = df_val.loc[i]\n",
    "  if curr_row.isna().sum() > 0:\n",
    "    curr_nan_cols = curr_row[curr_row.isna()].index\n",
    "    curr_row_knn = (df_val.loc[i] - knn_mean)/knn_std\n",
    "    nearest = df_knn.subtract(curr_row_knn,axis=1).pow(2).sum(axis=1).sort_values().index\n",
    "    curr_nan_cols_dict = {col: [] for col in curr_nan_cols}\n",
    "    k_limit = k*len(curr_nan_cols)\n",
    "    for j in nearest:\n",
    "      if j != i:\n",
    "        for col in curr_nan_cols:\n",
    "          if len(curr_nan_cols_dict[col]) < k:\n",
    "            curr_cell = df_train.loc[j][col]\n",
    "            if not np.isnan(curr_cell):\n",
    "              curr_nan_cols_dict[col].append(curr_cell)\n",
    "              k_limit -= 1\n",
    "      if k_limit == 0:\n",
    "        for key in curr_nan_cols_dict.keys():\n",
    "          df_val.loc[i,key] = pd.Series(curr_nan_cols_dict[key]).mean()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we repeat a similar process as we did for \"df_train\", only this time we are filling in values for \"df_val\". Notably, we are using the \"df_knn\" that was created from \"df_train\" to find the closest neighbors; it doesn't make too much sense to use the validation to fill in values for the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_csv(\"df_val_vfinal\")   #Used to save output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again we save our output to save time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>...</th>\n",
       "      <th>ecology_satisfactory</th>\n",
       "      <th>material_1.0</th>\n",
       "      <th>material_2.0</th>\n",
       "      <th>material_4.0</th>\n",
       "      <th>material_5.0</th>\n",
       "      <th>material_6.0</th>\n",
       "      <th>state_1.0</th>\n",
       "      <th>state_2.0</th>\n",
       "      <th>state_3.0</th>\n",
       "      <th>state_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25422</th>\n",
       "      <td>52</td>\n",
       "      <td>25.480000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1977.560000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.097032e+06</td>\n",
       "      <td>31167</td>\n",
       "      <td>0.109135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14917</th>\n",
       "      <td>88</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.984444e+06</td>\n",
       "      <td>142243</td>\n",
       "      <td>0.372735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11757</th>\n",
       "      <td>42</td>\n",
       "      <td>41.353313</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003.621928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.186638e+08</td>\n",
       "      <td>7538</td>\n",
       "      <td>0.551883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939554</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21055</th>\n",
       "      <td>34</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1971.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.799999e+06</td>\n",
       "      <td>76308</td>\n",
       "      <td>0.232656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13124</th>\n",
       "      <td>60</td>\n",
       "      <td>29.631892</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2013.304000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.307411e+06</td>\n",
       "      <td>75377</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq    life_sq  floor  max_floor   build_year  num_room  kitch_sq  \\\n",
       "25422       52  25.480000   15.0       17.0  1977.560000       2.0       0.0   \n",
       "14917       88  44.000000   11.0       24.0  1998.000000       2.0      11.0   \n",
       "11757       42  41.353313    3.0        0.0  2003.621928       1.0       0.0   \n",
       "21055       34  19.000000    1.0        9.0  1971.000000       1.0       6.0   \n",
       "13124       60  29.631892   13.0       17.0  2013.304000       2.0       1.0   \n",
       "\n",
       "             area_m  raion_popul  green_zone_part  ...  ecology_satisfactory  \\\n",
       "25422  8.097032e+06        31167         0.109135  ...                   0.0   \n",
       "14917  7.984444e+06       142243         0.372735  ...                   0.0   \n",
       "11757  1.186638e+08         7538         0.551883  ...                   0.0   \n",
       "21055  3.799999e+06        76308         0.232656  ...                   0.0   \n",
       "13124  7.307411e+06        75377         0.065444  ...                   0.0   \n",
       "\n",
       "       material_1.0  material_2.0  material_4.0  material_5.0  material_6.0  \\\n",
       "25422           1.0           0.0           0.0           0.0           0.0   \n",
       "14917           0.0           1.0           0.0           0.0           0.0   \n",
       "11757           1.0           0.0           0.0           0.0           0.0   \n",
       "21055           1.0           0.0           0.0           0.0           0.0   \n",
       "13124           1.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "       state_1.0  state_2.0  state_3.0  state_4.0  \n",
       "25422   0.000000   0.480000   0.520000        0.0  \n",
       "14917   0.000000   0.000000   1.000000        0.0  \n",
       "11757   0.939554   0.020821   0.039625        0.0  \n",
       "21055   0.000000   1.000000   0.000000        0.0  \n",
       "13124   1.000000   0.000000   0.000000        0.0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(\"df_val_vfinal\",index_col = \"Unnamed: 0\")\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we read in our output from before for \"df_val\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "counter = 0\n",
    "\n",
    "for i in df_test.index:\n",
    "  counter += 1\n",
    "  if counter % 50 == 0:\n",
    "    print(counter)\n",
    "  curr_row = df_test.loc[i]\n",
    "  if curr_row.isna().sum() > 0:\n",
    "    curr_nan_cols = curr_row[curr_row.isna()].index\n",
    "    curr_row_knn = (df_test.loc[i] - knn_mean)/knn_std\n",
    "    nearest = df_knn.subtract(curr_row_knn,axis=1).pow(2).sum(axis=1).sort_values().index\n",
    "    curr_nan_cols_dict = {col: [] for col in curr_nan_cols}\n",
    "    k_limit = k*len(curr_nan_cols)\n",
    "    for j in nearest:\n",
    "      if j != i:\n",
    "        for col in curr_nan_cols:\n",
    "          if len(curr_nan_cols_dict[col]) < k:\n",
    "            curr_cell = df_train.loc[j][col]\n",
    "            if not np.isnan(curr_cell):\n",
    "              curr_nan_cols_dict[col].append(curr_cell)\n",
    "              k_limit -= 1\n",
    "      if k_limit == 0:\n",
    "        for key in curr_nan_cols_dict.keys():\n",
    "          df_test.loc[i,key] = pd.Series(curr_nan_cols_dict[key]).mean()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again we repeat our process for filling in missing values, only this time for \"df_test\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"df_test_vfinal\")   #Used to save output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again we save our output to save time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>...</th>\n",
       "      <th>ecology_satisfactory</th>\n",
       "      <th>material_1.0</th>\n",
       "      <th>material_2.0</th>\n",
       "      <th>material_4.0</th>\n",
       "      <th>material_5.0</th>\n",
       "      <th>material_6.0</th>\n",
       "      <th>state_1.0</th>\n",
       "      <th>state_2.0</th>\n",
       "      <th>state_3.0</th>\n",
       "      <th>state_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>32</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.324134</td>\n",
       "      <td>1977.701274</td>\n",
       "      <td>1.718861</td>\n",
       "      <td>5.042330</td>\n",
       "      <td>6.206099e+06</td>\n",
       "      <td>111874</td>\n",
       "      <td>0.128123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083632</td>\n",
       "      <td>0.707033</td>\n",
       "      <td>0.209332</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24584</th>\n",
       "      <td>38</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.292112e+06</td>\n",
       "      <td>73148</td>\n",
       "      <td>0.063747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.068073</td>\n",
       "      <td>1973.690888</td>\n",
       "      <td>2.213239</td>\n",
       "      <td>6.813686</td>\n",
       "      <td>7.632940e+06</td>\n",
       "      <td>78810</td>\n",
       "      <td>0.051844</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719500</td>\n",
       "      <td>0.128544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391329</td>\n",
       "      <td>0.608671</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.745540</td>\n",
       "      <td>1963.437324</td>\n",
       "      <td>1.681712</td>\n",
       "      <td>6.049854</td>\n",
       "      <td>1.163805e+07</td>\n",
       "      <td>123280</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138487</td>\n",
       "      <td>0.477781</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.383034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.794906</td>\n",
       "      <td>0.205023</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>59</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.870405</td>\n",
       "      <td>1972.835403</td>\n",
       "      <td>2.200227</td>\n",
       "      <td>6.715337</td>\n",
       "      <td>1.488362e+07</td>\n",
       "      <td>72131</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703830</td>\n",
       "      <td>0.144197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413688</td>\n",
       "      <td>0.586312</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  floor  max_floor   build_year  num_room  kitch_sq  \\\n",
       "8193        32     16.0    4.0   9.324134  1977.701274  1.718861  5.042330   \n",
       "24584       38     18.0   16.0  16.000000  1973.000000  1.000000  9.000000   \n",
       "11          38     19.0   11.0  11.068073  1973.690888  2.213239  6.813686   \n",
       "13          31     31.0    4.0   6.745540  1963.437324  1.681712  6.049854   \n",
       "18          59     33.0   10.0  10.870405  1972.835403  2.200227  6.715337   \n",
       "\n",
       "             area_m  raion_popul  green_zone_part  ...  ecology_satisfactory  \\\n",
       "8193   6.206099e+06       111874         0.128123  ...                   0.0   \n",
       "24584  3.292112e+06        73148         0.063747  ...                   0.0   \n",
       "11     7.632940e+06        78810         0.051844  ...                   1.0   \n",
       "13     1.163805e+07       123280         0.068202  ...                   0.0   \n",
       "18     1.488362e+07        72131         0.024444  ...                   0.0   \n",
       "\n",
       "       material_1.0  material_2.0  material_4.0  material_5.0  material_6.0  \\\n",
       "8193       0.728819      0.000000      0.000000      0.271181           0.0   \n",
       "24584      0.000000      0.000000      0.000000      1.000000           0.0   \n",
       "11         0.719500      0.128544      0.000000      0.151956           0.0   \n",
       "13         0.138487      0.477781      0.000699      0.383034           0.0   \n",
       "18         0.703830      0.144197      0.000000      0.151974           0.0   \n",
       "\n",
       "       state_1.0  state_2.0  state_3.0  state_4.0  \n",
       "8193    0.083632   0.707033   0.209332   0.000004  \n",
       "24584   0.000000   0.000000   1.000000   0.000000  \n",
       "11      0.000000   0.391329   0.608671   0.000000  \n",
       "13      0.000000   0.794906   0.205023   0.000071  \n",
       "18      0.000000   0.413688   0.586312   0.000000  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"df_test_vfinal\",index_col = \"Unnamed: 0\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we read in our output from before for \"df_test\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(\"y_train_vfinal\")\n",
    "y_val.to_csv(\"y_val_vfinal\")\n",
    "y_test.to_csv(\"y_test_vfinal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also save our output for the response variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"y_train_vfinal\",index_col = \"Unnamed: 0\")\n",
    "y_val = pd.read_csv(\"y_val_vfinal\",index_col = \"Unnamed: 0\")\n",
    "y_test = pd.read_csv(\"y_test_vfinal\",index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we read in our response variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for_B(x, y, n):\n",
    "    # takes a data frame, and a numpy array\n",
    "    x = np.concatenate((np.ones((n,1)), x.to_numpy()), axis=1)\n",
    "    x_transpose = np.transpose(x)\n",
    "    return np.linalg.solve(np.matmul(x_transpose, x), x_transpose @ y)\n",
    "\n",
    "def get_predicted_values(beta, design_matrix, n):\n",
    "    return np.matmul(np.concatenate((np.ones((n,1)), design_matrix), axis = 1), beta)\n",
    "\n",
    "def BIC(predictions, actuals, d, n):\n",
    "    # numpy array - predictions, numpy array - actual \n",
    "    return (np.square(actuals - predictions).sum()) + (d * np.log(n))\n",
    "\n",
    "def RSquaredAdj(predictions, actuals, d, n):\n",
    "    x1 = np.square(actuals - actuals.mean()).sum()\n",
    "    x2 = np.square(predictions - actuals.mean()).sum()\n",
    "    r2 = x2/x1\n",
    "    return (1 - ((1 - r2) * (n - 1) / (n - d - 1)))\n",
    "\n",
    "def RMSE(predictions, actuals, n):\n",
    "    return np.sqrt((np.square(actuals - predictions).sum()) / n) \n",
    "\n",
    "def train_model(design_matrix, dependent_variable_series):\n",
    "    n = design_matrix.shape[0]\n",
    "    beta = solve_for_B(design_matrix, dependent_variable_series, n)\n",
    "    predicted_values = get_predicted_values(beta, design_matrix, n)\n",
    "    calculated_BIC = BIC(predicted_values, dependent_variable_series, d = design_matrix.shape[1], n = n)\n",
    "    calculated_RMSE = RMSE(predicted_values, dependent_variable_series, n = n)\n",
    "    residuals = predicted_values - dependent_variable_series\n",
    "    return beta, calculated_BIC, calculated_RMSE, residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are the functions used to train our linear regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_crossv_model(df, y): \n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(.25 * m)\n",
    "    train_1 = df.iloc[perm[:train_end]]\n",
    "    test_1 = y.iloc[perm[:train_end]]\n",
    "\n",
    "    train_2 = df.iloc[perm[train_end:train_end*2]]\n",
    "    test_2 = y.iloc[perm[train_end:train_end*2]]\n",
    "\n",
    "    train_3 = df.iloc[perm[train_end*2:train_end*3]]\n",
    "    test_3 = y.iloc[perm[train_end*2:train_end*3]]\n",
    "\n",
    "    train_4 = df.iloc[perm[train_end*3:]]\n",
    "    test_4 = y.iloc[perm[train_end*3:]]\n",
    "    return train_1, test_1, train_2, test_2, train_3, test_3, train_4, test_4\n",
    "\n",
    "\n",
    "def get_average_RMSE_for_one_model(df, y):\n",
    "    train_1, test_1, train_2, test_2, train_3, test_3, train_4, test_4 = train_crossv_model(df, y)\n",
    "\n",
    "    beta4, bic4, RMSE4, _ = train_model(train_1.append([train_2, train_3]), test_1.append([test_2, test_3]))\n",
    "\n",
    "    beta2, bic3,RMSE2, _ = train_model(train_1.append([train_4, train_3]), test_1.append([test_4, test_3]))\n",
    "\n",
    "    beta3, bic2, RMSE3, _ = train_model(train_1.append([train_2, train_4]), test_1.append([test_2, test_4]))\n",
    "\n",
    "    beta1, bic1, RMSE1, _ = train_model(train_4.append([train_2, train_3]), test_4.append([test_2, test_3]))\n",
    "\n",
    "    return sum([RMSE1, RMSE2, RMSE3, RMSE4]) / 4, sum([bic1, bic2, bic3, bic4]) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the code for our cross-validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# forward cross validated stepwise\n",
    "\n",
    "train_data = df_train.copy()\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "y_temp = y_train.copy()\n",
    "y_temp.reset_index(drop=True,inplace=True)\n",
    "df_with_col = pd.DataFrame()\n",
    "\n",
    "col_added = []\n",
    "rmses = []\n",
    "\n",
    "for i in range(0,50):\n",
    "\n",
    "    min_col = None\n",
    "    min_RMSE = 100000000000000000000\n",
    "    min_bic = 10000000000000000000\n",
    "\n",
    "    for col in train_data.columns:\n",
    "\n",
    "        df_with_col[col] = train_data[col]\n",
    "        \n",
    "        try:\n",
    "          new_RMSE, new_bic = get_average_RMSE_for_one_model(df_with_col, y_temp)\n",
    "                \n",
    "          if new_RMSE[0] <= min_RMSE:\n",
    "            min_bic = new_bic\n",
    "            min_RMSE = new_RMSE\n",
    "            min_col = col\n",
    "        except:\n",
    "          pass\n",
    "            \n",
    "        df_with_col.drop(columns=[col], inplace=True)\n",
    "\n",
    "    if min_col is not None:\n",
    "        print(min_col)\n",
    "        df_with_col[min_col] = train_data[min_col]\n",
    "        train_data.drop(columns=[min_col], inplace=True)\n",
    "        rmses.append(min_RMSE)\n",
    "        print(\"bic: \" + str(min_bic))\n",
    "        print(\"rmse: \" + str(min_RMSE))\n",
    "        col_added.append(min_col)\n",
    "        print(\"\")\n",
    "    else:\n",
    "        print(\"Failed #2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is our code for the forward stepwise regression. We use it to find the top 50 variables that we believe minimie the RMSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cols = df.columns\n",
    "m_cols = macro.columns\n",
    "t_c = 0\n",
    "m_c = 0\n",
    "for col in col_added:\n",
    "    if col in t_cols:\n",
    "        t_c += 1\n",
    "    elif col in m_cols:\n",
    "        m_c += 1\n",
    "    else:\n",
    "        print(col)\n",
    "print(\"t: \" + str(t_c) + \" | m: \" + str(m_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to abide by the projects specifications, we cannot use more than 10 variables from the \"macro.csv\" file. Here we count each of the variables found in the stepwise regression to see which ones came from \"train.csv\" and which ones came from \"macro.csv\". We ended up having all 50 of our variables coming from \"train.csv\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(col_added)):\n",
    "    print(i)\n",
    "    col_added_mod = col_added[:-i]\n",
    "    df_train_final = df_train[col_added_mod]\n",
    "    df_val_final = df_val[col_added_mod]\n",
    "    df_test_final = df_test[col_added_mod]\n",
    "    df_train_final_norm = (df_train_final-df_train_final.mean())/df_train_final.std()\n",
    "    y_train_final_norm = (y_train_final-y_train_final.mean())/y_train_final.std()\n",
    "\n",
    "    df_val_final_norm = (df_val_final-df_val_final.mean())/df_val_final.std()\n",
    "    y_val_final_norm = (y_val_final-y_val_final.mean())/y_val_final.std()\n",
    "\n",
    "    df_test_final_norm = (df_test_final-df_test_final.mean())/df_test_final.std()\n",
    "    y_test_final_norm = (y_test_final-y_test_final.mean())/y_test_final.std()\n",
    "    \n",
    "    betas = linearRegression(df_train_final_norm,y_train_final_norm)\n",
    "    print(np.square(df_train_final_norm.dot(betas).to_numpy() - y_train_final_norm.to_numpy()).mean())\n",
    "    print(np.square(df_val_final_norm.dot(betas).to_numpy() - y_val_final_norm.to_numpy()).mean())\n",
    "    print(np.square(df_test_final_norm.dot(betas).to_numpy() - y_test_final_norm.to_numpy()).mean())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of our 50 variables, we wanted to further dive deeper to find out if all of them are actually predictive. To do so, we would the training, validation, and testing MSE using the top 50 variables, then the top 49, and so on until we iterated through the whole list. Then, rather than picking the one that had the lowest MSE for validation and testing, we chose one that we believed had a relatively low MSE while still maintaining as many variables as possible. We did this because we believed that the neural network might be able to pick up more information if more variables were available.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_added_mod = col_added[:-16]\n",
    "\n",
    "df_train_final = df_train[col_added_mod]\n",
    "df_val_final = df_val[col_added_mod]\n",
    "df_test_final = df_test[col_added_mod]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We settled on choosing the top 34 variables from our original 50.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final.to_csv(\"df_train_vvfinal\")\n",
    "df_val_final.to_csv(\"df_val_vvfinal\")\n",
    "df_test_final.to_csv(\"df_test_vvfinal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we save the output so we do not have to repeat this process every time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = pd.read_csv(\"df_train_vvfinal\", index_col = \"Unnamed: 0\")\n",
    "df_val_final = pd.read_csv(\"df_val_vvfinal\", index_col = \"Unnamed: 0\")\n",
    "df_test_final = pd.read_csv(\"df_test_vvfinal\", index_col = \"Unnamed: 0\")\n",
    "\n",
    "y_train_final = pd.read_csv(\"y_train_vfinal\", index_col = \"Unnamed: 0\")\n",
    "y_val_final = pd.read_csv(\"y_val_vfinal\", index_col = \"Unnamed: 0\")\n",
    "y_test_final = pd.read_csv(\"y_test_vfinal\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we read in our previous files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final_norm = (df_train_final-df_train_final.mean())/df_train_final.std()\n",
    "y_train_final_norm = (y_train_final-y_train_final.mean())/y_train_final.std()\n",
    "\n",
    "df_val_final_norm = (df_val_final-df_val_final.mean())/df_val_final.std()\n",
    "y_val_final_norm = (y_val_final-y_val_final.mean())/y_val_final.std()\n",
    "\n",
    "df_test_final_norm = (df_test_final-df_test_final.mean())/df_test_final.std()\n",
    "y_test_final_norm = (y_test_final-y_test_final.mean())/y_test_final.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In hopes of improving our MSE, we standardized all of our values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegression(X_train,y_train):\n",
    "  betas = np.linalg.inv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "  return betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A simple linear regression function to produce the betas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = linearRegression(df_train_final_norm,y_train_final_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the betas from the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5303807714384899\n",
      "0.8942350556889913\n",
      "0.9829514749410203\n"
     ]
    }
   ],
   "source": [
    "print(np.square(df_train_final_norm.dot(betas).to_numpy() - y_train_final_norm.to_numpy()).mean())\n",
    "print(np.square(df_val_final_norm.dot(betas).to_numpy() - y_val_final_norm.to_numpy()).mean())\n",
    "print(np.square(df_test_final_norm.dot(betas).to_numpy() - y_test_final_norm.to_numpy()).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we can see our final MSE values for the training, validation, and testing set respectively. Thus our goal for the neural network is to try and beat this testing MSE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Neural Network</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***In this section we create our neural network and tune it. Due to the difficulties we had in with instabilitiy, each person in our group had their own version of the neural network class. The one below is one of these versions.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(): \n",
    "    def fit(self, X, y, n_hidden, nodes, activations, lr, validation_X, validation_y, batch_size = 0):\n",
    "        self._lr = lr # Learning Rate\n",
    "        self._X = X.values # X train for Training\n",
    "        self._y = y.values # y train for Training\n",
    "        self._n_hidden = n_hidden # number of hidden layres\n",
    "        self._nodes = nodes # Dimensions of nodes for each layer\n",
    "        self._weights = self._generate_weights() # Matrix of Weights\n",
    "        self._biases = self._generate_bias() # Matrix of Biases\n",
    "        self._activations = activations # What activation to use on each layer\n",
    "        self._forward_inputs = [] # Keeping track of historical forward input\n",
    "        self._val_X = validation_X.values # Validation X set for Prediction\n",
    "        self._val_y = validation_y.values # Validation y set for Prediction\n",
    "        self._batch_size = batch_size # What batch size for SGD (0 means no SGD)\n",
    "        \n",
    "\n",
    "        return self._train()\n",
    "    \"\"\"\n",
    "    Predict on Validation Data\n",
    "        X - Validation Data\n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        pred = X\n",
    "        weights = self._weights\n",
    "        biases = self._biases\n",
    "        activations = self._activations[1:-1]\n",
    "    \n",
    "        for idx, layer in enumerate(weights):\n",
    "            if idx == (len(weights) - 1):\n",
    "                pred = (pred @ layer) + biases[idx].T,\n",
    "            else:\n",
    "                weight_output = (pred @ layer) + biases[idx].T\n",
    "                pred = self._activation(data = weight_output, activation = activations[idx])\n",
    "\n",
    "        return pred[0]\n",
    "    \"\"\"\n",
    "    Function containing all our activation functions\n",
    "        data - ypred\n",
    "        activation - what activation function we choose to use\n",
    "    \"\"\"    \n",
    "    def _activation(self, data, activation = \"relu\"):\n",
    "        if activation == \"relu\":\n",
    "            def relu(data):\n",
    "                return np.array([max(0,i) for i in data]).reshape(data.shape)\n",
    "            return np.apply_along_axis(relu, 1, data)\n",
    "        if activation == \"sigmoid\":\n",
    "            def sigmoid(data):\n",
    "                return (1/(1 + np.exp(-data))).reshape(data.shape)\n",
    "            return np.apply_along_axis(sigmoid, 1, data)\n",
    "    \"\"\"\n",
    "    Function containing all our derivative activation functions\n",
    "        points - ypred\n",
    "        activation - what activation function we choose to use\n",
    "    \"\"\" \n",
    "    def _der_activation(self, points, activation = \"relu\"):\n",
    "        if activation == \"relu\":\n",
    "            def d_relu(point):\n",
    "                return np.array([0 if y <= 0 else 1 for y in point])\n",
    "            return np.apply_along_axis(d_relu, 1, points)\n",
    "        if activation == \"sigmoid\":\n",
    "            ## todo\n",
    "            return\n",
    "    \"\"\"\n",
    "    Function containing all our loss funtions\n",
    "        ypred - ypred\n",
    "        loss - what loss function we choose to use\n",
    "    \"\"\"\n",
    "    def _loss_function(self, ypred, loss = \"l2\"):\n",
    "        y = self._val_y\n",
    "        if loss == \"mse\":\n",
    "            return ((ypred - y) ** 2).mean()\n",
    "        if loss == \"l2\":\n",
    "            return (((ypred - y) ** 2)/2).mean()\n",
    "    \"\"\"\n",
    "    Giving us the Jacobian of our losses\n",
    "        ypred - ypred\n",
    "        loss - what loss function we choose to use\n",
    "    \"\"\"\n",
    "    def _loss_jacobian(self, ypred, loss = \"l2\"):\n",
    "        if self._batch_size > 0:\n",
    "            y = self._batchy\n",
    "        else:\n",
    "            y = self._y\n",
    "        if loss == \"l2\":\n",
    "            return (ypred - y)/(len(ypred))\n",
    "    \"\"\"\n",
    "    Initialize the weights for NN using Normal Distribution\n",
    "    \"\"\"\n",
    "    def _generate_weights(self):\n",
    "        hidden_weights = []\n",
    "        nodes = self._nodes\n",
    "        for idx in range(1,len(nodes)):\n",
    "            hidden_weights.append(0.1 * np.random.randn(nodes[idx -1], nodes[idx]))\n",
    "            #hidden_weights.append(0.01 *np.random.randn(nodes[idx -1], nodes[idx]))\n",
    "\n",
    "        return hidden_weights\n",
    "    \"\"\"\n",
    "    Initialize the biases for NN using array of all 0's\n",
    "    \"\"\"\n",
    "    def _generate_bias(self):\n",
    "        hidden_layers = []\n",
    "        nodes = self._nodes\n",
    "        for i in range(self._n_hidden + 1):\n",
    "            hidden_layers.append(np.zeros((nodes[i + 1], 1)))\n",
    "        return hidden_layers\n",
    "    \n",
    "    \"\"\"\n",
    "    Forward Propagation for the NN\n",
    "    \"\"\"\n",
    "    def _forward_propagation(self):\n",
    "        \"\"\"\n",
    "        Suppose 2 observations\n",
    "        \n",
    "        Suppose previous layer is 3 nodes\n",
    "        Suppose current layer is 2 nodes\n",
    "        \n",
    "        prev shape (2,3)\n",
    "        prev = ob1 [prev_node_1 val, prev_node_2 val, prev_node_3 val]\n",
    "               ob2 [prev_node_1 val, prev_node_2 val, prev_node_3 val]\n",
    "               \n",
    "        layer shape (3,2)\n",
    "        layer = [weight for current_node_1 for prev_node_1, weight for current_node_2 for prev_node_1]\n",
    "                [weight for current_node_1 for prev_node_2, weight for current_node_2 for prev_node_2]\n",
    "                [weight for current_node_1 for prev_node_3, weight for current_node_2 for prev_node_3]\n",
    "                \n",
    "        output shape (2,2) # since 2 observations and 2 layers\n",
    "        output = ob1 [current_node_1 val, current_node_2 val]\n",
    "                 ob2 [current_node_1 val, current_node_2 val]\n",
    "                 \n",
    "        Then for bias in current layer it is (2,1) since 2 nodes in current layer\n",
    "        \n",
    "        So for each row in output we add the bias row wise and apply the activation function to each row\n",
    "        \n",
    "        prev <- ouput\n",
    "        \n",
    "        Move onto next layer...\n",
    "        \"\"\"\n",
    "        if self._batch_size > 0:\n",
    "            prev = self._batchX\n",
    "        else:\n",
    "            prev = self._X\n",
    "        weights = self._weights\n",
    "        biases = self._biases\n",
    "        activations = self._activations[1:-1]\n",
    "    \n",
    "        for idx, layer in enumerate(weights):\n",
    "            if idx == (len(weights) - 1):\n",
    "                self._forward_inputs.append((prev, None))\n",
    "                prev = (prev @ layer) + biases[idx].T,\n",
    "            else:\n",
    "                weight_output = (prev @ layer) + biases[idx].T\n",
    "                self._forward_inputs.append((prev, weight_output))\n",
    "                prev = self._activation(data = weight_output, activation = activations[idx])\n",
    "\n",
    "        return prev\n",
    "    \"\"\"\n",
    "    Backward propagation for the NN\n",
    "    \"\"\"\n",
    "    def _backward_propagation(self, ypred):\n",
    "            \n",
    "        j = self._loss_jacobian(ypred)\n",
    "                \n",
    "        for i in range(len(self._forward_inputs)-1, -1, -1):\n",
    "            if i != (len(self._forward_inputs) - 1):\n",
    "                # activation func on all layers except the last\n",
    "                der_acti = self._der_activation(self._forward_inputs[i][1])\n",
    "                j = np.multiply(j,der_acti)\n",
    "\n",
    "            x = self._forward_inputs[i][0]\n",
    "\n",
    "            jw = x.T.dot(j)\n",
    "\n",
    "            b = np.ones((j.shape[0],1))\n",
    "            jb = j.T.dot(b)\n",
    "            \n",
    "            j = j.dot(self._weights[i].T)\n",
    "            \n",
    "            self._weights[i] -= self._lr * jw\n",
    "            self._biases[i] -= self._lr * jb\n",
    "            \n",
    "        self._forward_inputs = []        \n",
    "    \"\"\"\n",
    "    Training the NN using Annealing and Patience Thresholds\n",
    "    \"\"\"\n",
    "    def _train(self):\n",
    "        min_loss = old_loss = np.inf\n",
    "        losses = []\n",
    "        mses = []\n",
    "        tol = 0.00001\n",
    "        terminate_count = anneal_count = step_count = 0\n",
    "        while True:\n",
    "            if self._batch_size > 0:\n",
    "                X_index = np.arange(self._X.shape[0])\n",
    "                np.random.shuffle(X_index)\n",
    "                batch_index = X_index[:self._batch_size]\n",
    "                self._batchX = self._X[batch_index,:]\n",
    "                self._batchy = self._y[batch_index,:]\n",
    "            \n",
    "            batched_out = self._forward_propagation()\n",
    "            validation_out = self.predict(self._val_X)\n",
    "                \n",
    "            loss = self._loss_function(validation_out)\n",
    "            mse = self._loss_function(validation_out, loss = \"mse\")\n",
    "            print(\"\\nloss:\")\n",
    "            print(loss)\n",
    "            print(\"mse:\")\n",
    "            print(mse)\n",
    "            if loss <= min_loss:\n",
    "                min_loss = loss\n",
    "                if loss <= (min_loss - 0.1):\n",
    "                    terminate_count = anneal_count = 0\n",
    "            if loss <= old_loss:\n",
    "                anneal_count = 0\n",
    "            else:\n",
    "                terminate_count += 1\n",
    "                anneal_count += 1\n",
    "                print(\"INCREASE IN LOSS\")\n",
    "                if anneal_count >= 2:\n",
    "                    anneal_count = 0\n",
    "                    self._lr = self._lr / 2\n",
    "                    print(\"Decreasing learning rate. New rate is \" + str(self._lr))\n",
    "                if terminate_count > 10:\n",
    "                    break\n",
    "            if step_count > 35:\n",
    "                self._lr = self._lr * 0.9\n",
    "                print(\"Annealing learning rate. New rate is \" + str(self._lr))\n",
    "                step_count = 0\n",
    "            if self._lr < tol:\n",
    "                break\n",
    "            \n",
    "            losses.append(loss)\n",
    "            mses.append(mse)\n",
    "            self._backward_propagation(batched_out[0])\n",
    "            old_loss = loss\n",
    "            step_count += 1\n",
    "            \n",
    "        return losses, mses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we create our neural network class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = df_train_final_norm.shape[1]\n",
    "OUTPUT_SIZE = 1\n",
    "LEARNING_RATE = 0.5\n",
    "nodes = [INPUT_SIZE,34,34,34,34,34,OUTPUT_SIZE]\n",
    "activations = [\"relu\" for i in range(len(nodes))]\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "nn.fit(X = df_train_final_norm,\n",
    "       y = y_train_final_norm,\n",
    "       n_hidden = len(nodes) - 2,\n",
    "       nodes = nodes,\n",
    "       activations = activations,\n",
    "       lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Originally, we wanted to create a grid search to test various model parameters. Unfortunately, we encountered numerous instabilities while training our model that made this unfeasible. Therefore, we resorted to manually testing different hyperparameter combinations, adjusting and tuning the model (such as the annealing rate and termination criterion) to make sure it worked correctly. To split up the work, each person in our group tested different combinations of hyperparameters, and thus had slightly different methods of tuning the model. To decide on the best model, we settled on the one that had the lowest validation MSE after training on the training data. We found that the model with 5 layers of 34 nodes each was the best.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn.predict(df_test_final_norm)\n",
    "test_mse = ((predictions - y_test_final_norm) ** 2).mean()\n",
    "test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After determining the best model, we calculated out the test MSE to compare to the MSE acquired by using linear regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Width</th>\n",
       "      <th>Initial Learning Rate</th>\n",
       "      <th>Validation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>102</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102</td>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nodes  Width  Initial Learning Rate  Validation MSE\n",
       "2      34      5                   0.75           0.359\n",
       "1      34      3                   0.60           0.366\n",
       "0      34      1                   0.50           0.373\n",
       "5      34     10                   1.00           0.374\n",
       "4      34      8                   1.00           0.383\n",
       "3      34      7                   1.00           0.386\n",
       "8      68      5                   0.40           0.394\n",
       "11    102      1                   0.40           0.402\n",
       "7      68      3                   0.50           0.405\n",
       "13    102      5                   0.40           0.406\n",
       "6      68      1                   0.50           0.409\n",
       "14    102      7                   0.40           0.425\n",
       "9      68      7                   0.40           0.437\n",
       "10     68     10                   0.40           0.453\n",
       "12    102      3                   0.40           0.463"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.DataFrame(data={\"Nodes\":[34,34,34,34,34,34,68,68,68,68,68,102,102,102,102],\n",
    "                  \"Width\":[1,3,5,7,8,10,1,3,5,7,10,1,3,5,7],\n",
    "                  \"Initial Learning Rate\":[0.5,0.6,0.75,1,1,1,0.5,0.5,0.4,0.4,0.4,0.4,0.4,0.4,0.4],\n",
    "                  \"Validation MSE\":[0.373, 0.366, 0.359, 0.386, 0.383, 0.374,\n",
    "                                   0.409, 0.405, 0.394, 0.437, 0.453,\n",
    "                                   0.402, 0.463, 0.406, 0.425]})\n",
    "\n",
    "final_results.sort_values(by=\"Validation MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we can see the final results of all the neural networks we trained, ordered by validation MSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_final = pd.DataFrame(data={\"Model\":[\"LR\", \"NN 1x34\", \"NN 3x34\", \"NN 5x34\"],\n",
    "                               \"Test MSE\":[0.983, 1.07405, 1.008034, 0.596636]})\n",
    "ax = test_final.plot.bar(x='Model', y='Test MSE', rot=0,\n",
    "                         fontsize = 16, legend=False, figsize = (8,8),\n",
    "                         color = [\"r\",\"b\",\"b\",\"lightskyblue\"]);\n",
    "ax.set_xlabel(\"Model\", fontsize=18);\n",
    "ax.set_ylabel(\"Test MSE\", fontsize=18);\n",
    "ax.set_title(\"Best Models - Test MSE Comparison\", fontsize = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we can see an overall comparison of our linear regression model (red) and our top three neural networks (blue and cyan) by testing MSE. Interestingly, while each neural network had a better validation MSE against the linear regression, all but one of the neural networks had a worse testing MSE. Fortunately, our best neural network model (cyan) had a much better testing MSE than our linear regression model.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
